#!/usr/bin/python3

# dmedia: distributed media library
# Copyright (C) 2013 Novacut Inc
#
# This file is part of `dmedia`.
#
# `dmedia` is free software: you can redistribute it and/or modify it under
# the terms of the GNU Affero General Public License as published by the Free
# Software Foundation, either version 3 of the License, or (at your option) any
# later version.
#
# `dmedia` is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE.  See the GNU Affero General Public License for more
# details.
#
# You should have received a copy of the GNU Affero General Public License along
# with `dmedia`.  If not, see <http://www.gnu.org/licenses/>.
#
# Authors:
#   Jason Gerard DeRose <jderose@novacut.com>

from filestore.migration import Migration
from microfiber import Server, encode_attachment, Attachment, NotFound, dumps

import dmedia
from dmedia.util import get_db
from dmedia.metastore import MetaStore, BufferedSave
from dmedia import migration
from dmedia import schema
from dmedia.service import get_env


log = dmedia.configure_logging()
env = get_env()


def create_mapping_doc(v0_id, v1_ch):
    v1_leaf_hashes = Attachment('application/octet-stream', v1_ch.leaf_hashes)
    return {
        '_id': v0_id,
        '_attachments': {
            'v1_leaf_hashes': encode_attachment(v1_leaf_hashes),
        },
        'bytes': v1_ch.file_size,
        'v1_id': v1_ch.id,
    }


server = Server(env)
src = server.database('dmedia-0')
dst = server.database('dmedia-1')
log_db = server.database('log-1')
mdb = server.database('migrate-0-to-1')
ms = MetaStore(dst)

src.post(None, '_compact')  # Go ahead and clean up

# Re-hash V0 to V1 file ID:
print('\nRe-hashing files to map V0 IDs to V1...')
print('(This can take a *long* time, but can be resumed where you left off)\n')
mdb.ensure()
buf = BufferedSave(mdb)
local_stores = ms.get_local_stores()
try:
    for fs in local_stores:
        print(fs)
        mig = Migration(fs.parentdir)
        if not mig.needs_migration():
            log.info('%r does not need upgrade', fs)
            print('    does not need upgrade')
            continue
        for (v0_id, v1_id, v1_ch) in mig:
            if v1_ch is not None:
                doc = create_mapping_doc(v0_id, v1_ch)
                log.info(v0_id)
                buf.save(doc)
        buf.flush()
        print('    {} files; {} conflicts'.format(buf.count, buf.conflicts))
finally:
    buf.flush()
print('total: {} files; {} conflicts\n'.format(buf.count, buf.conflicts))


# Migrate dmedia/store docs:
print('Upgrading dmedia/store docs...')
buf = BufferedSave(dst)
for row in src.view('doc', 'type', key='dmedia/store')['rows']:
    old = src.get(row['id'])
    new = migration.migrate_store(old)
    buf.save(new)
buf.flush()
print('dmedia/store: {} docs; {} conflicts\n'.format(buf.count, buf.conflicts))


# Migrate dmedia/file:
print('Upgrading dmedia/file docs...')
buf = BufferedSave(dst)
limit = 25
skip = 0
while True:
    rows = src.view('doc', 'type',
        key='dmedia/file',
        limit=limit,
        skip=skip,
        include_docs=True,
    )['rows']
    if not rows:
        break
    skip += len(rows)
    for row in rows:
        old = row['doc']
        v0_id = old['_id']
        try:
            m = mdb.get(v0_id, attachments=True)
        except NotFound:
            print('Not Found', v0_id)
            continue
        new = migration.migrate_file(old, m)
        buf.save(new)
buf.flush()
print('dmedia/file: {} docs; {} conflicts\n'.format(buf.count, buf.conflicts))


# Migrate dmedia/log:
print('Upgrading dmedia/log docs...')
log_db.ensure()
buf = BufferedSave(log_db)
skip = 0
while True:
    rows = src.view('doc', 'type',
        key='dmedia/log',
        limit=25,
        skip=skip,
        include_docs=True,
    )['rows']
    if not rows:
        break
    skip += len(rows)
    for row in rows:
        old = row['doc']
        file_id = old['file_id']
        try:
            mdoc = mdb.get(file_id)
        except NotFound:
            print('Not Found', file_id)
            continue
        new = migration.migrate_log(old, mdoc)
        buf.save(new)
buf.flush()
print('dmedia/log: {} docs; {} conflicts\n'.format(buf.count, buf.conflicts))


# Migrate dmedia/project docs:
print('Upgrading dmedia/project docs...')
buf = BufferedSave(dst)
for row in src.view('doc', 'type', key='dmedia/project')['rows']:
    old = src.get(row['id'], attachments=True)
    new = migration.migrate_project(old)
    buf.save(new)
buf.flush()
print('dmedia/project: {} docs; {} conflicts\n'.format(buf.count, buf.conflicts))


# Migrate dmedia/batch docs:
print('Upgrading dmedia/batch docs...')
buf = BufferedSave(dst)
for row in src.view('doc', 'type', key='dmedia/batch')['rows']:
    old = src.get(row['id'], attachments=True)
    new = migration.migrate_batch(old)
    buf.save(new)
buf.flush()
print('dmedia/batch: {} docs; {} conflicts\n'.format(buf.count, buf.conflicts))


def iter_id_map(old):
    ids = [f.get('id') for f in old['files'].values()]
    for doc in mdb.get_many(ids):
        if doc is not None:
            yield (doc['_id'], doc['v1_id'])


# Migrate dmedia/import docs:
print('Upgrading dmedia/import docs...')
buf = BufferedSave(dst)
for row in src.view('doc', 'type', key='dmedia/import')['rows']:
    old = src.get(row['id'], attachments=True)
    id_map = dict(iter_id_map(old))
    new = migration.migrate_import(old, id_map)
    buf.save(new)
buf.flush()
print('dmedia/import: {} docs; {} conflicts\n'.format(buf.count, buf.conflicts))


# Migrate project databases:
print('Upgrading Dmedia project databases...')
for (v0_name, v0_id) in migration.iter_v0_project_dbs(server):
    v1_id = migration.b32_to_db32(v0_id)
    v1_name = schema.project_db_name(v1_id)
    src = server.database(v0_name)
    src.post(None, '_compact')  # Go ahead and clean up
    dst = server.database(v1_name)
    dst.ensure()
    buf = BufferedSave(dst)
    print('\n{} => {}'.format(v0_name, v1_name))
    kw = {'limit': 50, 'skip': 0}
    while True:
        rows = src.get('_all_docs', **kw)['rows']
        if not rows:
            break
        kw['skip'] += len(rows)
        for row in rows:
            _id = row['id']
            if _id.startswith('_'):
                continue
            old = src.get(_id, attachments=True)
            v0_id = old['_id']
            _type = old.get('type')
            if _type == 'dmedia/file':
                try:
                    m = mdb.get(v0_id)
                except NotFound:
                    print('Not Found', v0_id)
                    continue
                new = migration.migrate_project_file(old, m['v1_id'])
                buf.save(new)
            elif _type == 'dmedia/project':
                new = migration.migrate_project(old)
                buf.save(new)
            elif _type == 'dmedia/import':
                id_map = dict(iter_id_map(old))
                new = migration.migrate_import(old, id_map)
                buf.save(new)
            else:
                print('WARNING: unexpected type {!r} for {}'.format(_type, v0_id)) 
    buf.flush()
    print('{}: {} docs; {} conflicts'.format(v1_name, buf.count, buf.conflicts))


print('\nV0 => V1 Upgrade Sucessfull!')
