#!/usr/bin/python3

# dmedia: distributed media library
# Copyright (C) 2013 Novacut Inc
#
# This file is part of `dmedia`.
#
# `dmedia` is free software: you can redistribute it and/or modify it under
# the terms of the GNU Affero General Public License as published by the Free
# Software Foundation, either version 3 of the License, or (at your option) any
# later version.
#
# `dmedia` is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE.  See the GNU Affero General Public License for more
# details.
#
# You should have received a copy of the GNU Affero General Public License along
# with `dmedia`.  If not, see <http://www.gnu.org/licenses/>.
#
# Authors:
#   Jason Gerard DeRose <jderose@novacut.com>

from filestore import Migration
from microfiber import Database, dmedia_env, encode_attachment, Attachment, NotFound, dumps

import dmedia
from dmedia.util import get_db
from dmedia.metastore import MetaStore, BufferedSave
from dmedia.migration import migrate_file, migrate_store, migrate_project, migrate_batch, migrate_import


log = dmedia.configure_logging()


def create_mapping_doc(v0_id, v1_ch):
    v1_leaf_hashes = Attachment('application/octet-stream', v1_ch.leaf_hashes)
    return {
        '_id': v0_id,
        '_attachments': {
            'v1_leaf_hashes': encode_attachment(v1_leaf_hashes),
        },
        'bytes': v1_ch.file_size,
        'v1_id': v1_ch.id,
    }


src = Database('dmedia-0', dmedia_env())
dst = src.database('dmedia-1')
mdb = src.database('migrate-0-to-1')
ms = MetaStore(dst)

# Re-hash V0 to V1 file ID:
print('\nRe-hashing files to map V0 IDs to V1 IDs...')
print('(This can take a *long* time, but can be resumed where you left off)')
mdb.ensure()
buf = BufferedSave(mdb)
local_stores = ms.get_local_stores()
try:
    for fs in local_stores:
        print(fs)
        if not fs.needs_migration:
            log.info('FileStore %s at %r does not need migration', fs.id, fs.parentdir)
            print('    does not need migration')
            continue
        migration = Migration(fs)
        for (v0_id, v1_id, v1_ch) in migration:
            if v1_ch is not None:
                doc = create_mapping_doc(v0_id, v1_ch)
                log.info(v0_id)
                buf.save(doc)
        buf.flush()
        print('    {} files; {} conflicts'.format(buf.count, buf.conflicts))
finally:
    buf.flush()
print('total: {} files; {} conflicts\n'.format(buf.count, buf.conflicts))


# Migrate dmedia/store docs:
print('Migrating dmedia/store docs...')
buf = BufferedSave(dst)
for row in src.view('doc', 'type', key='dmedia/store')['rows']:
    old = src.get(row['id'])
    new = migrate_store(old)
    buf.save(new)
buf.flush()
print('dmedia/store: {} docs; {} conflicts\n'.format(buf.count, buf.conflicts))


# Migrate dmedia/file:
print('Migrating dmedia/file docs...')
buf = BufferedSave(dst)
limit = 25
skip = 0
while True:
    rows = src.view('doc', 'type',
        key='dmedia/file',
        limit=limit,
        skip=skip,
        include_docs=True,
    )['rows']
    if not rows:
        break
    skip += len(rows)
    for row in rows:
        old = row['doc']
        v0_id = old['_id']
        try:
            m = mdb.get(v0_id, attachments=True)
        except NotFound:
            print('Not Found', v0_id)
            continue
        new = migrate_file(old, m)
        buf.save(new)
buf.flush()
print('dmedia/file: {} docs; {} conflicts\n'.format(buf.count, buf.conflicts))


# Migrate dmedia/project docs:
print('Migrating dmedia/project docs...')
buf = BufferedSave(dst)
for row in src.view('doc', 'type', key='dmedia/project')['rows']:
    old = src.get(row['id'], attachments=True)
    new = migrate_project(old)
    buf.save(new)
buf.flush()
print('dmedia/project: {} docs; {} conflicts\n'.format(buf.count, buf.conflicts))


# Migrate dmedia/batch docs:
print('Migrating dmedia/batch docs...')
buf = BufferedSave(dst)
for row in src.view('doc', 'type', key='dmedia/batch')['rows']:
    old = src.get(row['id'], attachments=True)
    new = migrate_batch(old)
    buf.save(new)
buf.flush()
print('dmedia/batch: {} docs; {} conflicts\n'.format(buf.count, buf.conflicts))


def iter_id_map(old):
    ids = [f.get('id') for f in old['files'].values()]
    for doc in mdb.get_many(ids):
        if doc is not None:
            yield (doc['_id'], doc['v1_id'])


# Migrate dmedia/import docs:
print('Migrating dmedia/import docs...')
buf = BufferedSave(dst)
for row in src.view('doc', 'type', key='dmedia/import')['rows']:
    old = src.get(row['id'], attachments=True)
    id_map = dict(iter_id_map(old))
    new = migrate_import(old, id_map)
    buf.save(new)
buf.flush()
print('dmedia/import: {} docs; {} conflicts\n'.format(buf.count, buf.conflicts))
